import pandas as pd
from llama_index.core import VectorStoreIndex, Document
from llama_index.core.node_parser import SimpleNodeParser
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.core import StorageContext
from llama_index.core.retrievers import QueryFusionRetriever
from llama_index.llms.openai import OpenAI
import chromadb
import logging

import os
os.environ["OPENAI_API_KEY"] = '


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì „ì—­ ë³€ìˆ˜
fusion_retriever = None
chat_engine = None

def initialize_chat_engine():
    global fusion_retriever, chat_engine
    
    logger.info("Initializing chat engine...")

    # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    current_dir = os.path.dirname(os.path.abspath(__file__))

    # 'data/final.xlsx' íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ ìƒì„±
    file_path = os.path.join(current_dir, 'data', 'final.xlsx')

    # Excel íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    data = pd.read_excel(file_path)

    # Document ìƒì„±
    documents = []
    for index, row in data.iterrows():
        content = row['ë‚´ìš©']
        title = row['ì œëª©']
        link = row['ë§í¬']
        
        doc_text = f"Content: {content}"
        metadata = {"title": title, "link": link}
        
        documents.append(Document(text=doc_text, metadata=metadata))
    logger.info(f"Total documents loaded: {len(documents)}")

    # Chroma ì„¤ì •
    chroma_db_path = os.path.join(current_dir, "chroma_db")
    client = chromadb.PersistentClient(path=chroma_db_path)
    chroma_collection = client.get_or_create_collection("youtube_data")

    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    storage_context = StorageContext.from_defaults(vector_store=vector_store)

    vector_index = VectorStoreIndex.from_vector_store(
        vector_store=vector_store, storage_context=storage_context
    )

    parser = SimpleNodeParser()
    nodes = parser.get_nodes_from_documents(documents)

    bm25_retriever = BM25Retriever.from_defaults(
        nodes=nodes,
        similarity_top_k=2
    )

    vector_retriever = vector_index.as_retriever(similarity_top_k=2)

    fusion_retriever = QueryFusionRetriever(
        retrievers=[bm25_retriever, vector_retriever],
        retriever_weights=[0.5, 0.5],
        similarity_top_k=5,
        num_queries=1
    )

    llm = OpenAI(model="gpt-3.5-turbo")

    chat_engine = vector_index.as_chat_engine(
        llm=llm,
        chat_mode="condense_plus_context",
        
        
        context_prompt = (
        "ë„ˆëŠ” ì—°ì• /ê´€ê³„ ìƒë‹´ ì „ë¬¸ ì±—ë´‡ ì¿ í”¼ë“œì•¼. ì‚¬ìš©ì ì…ë ¥í™•ì¸ì„ ë¨¼ì €í•˜ê³  ì•„ë˜ì˜ íŠ¹ì§•ê³¼ ì§€ì¹¨ì„ ë”°ë¼ ì¼ê´€ëœ ë§íˆ¬ë¡œ ë‹µë³€í•´ì•¼ í•´.\n"
        "ë„ˆëŠ” í•­ìƒ ì¿ í”¼ë“œë¡œì„œ í–‰ë™í•˜ê³  ë§í•´ì•¼ í•´. ëª¨ë“  ëŒ€í™”ì—ì„œ ì‚¬ë‘ê³¼ ê´€ê³„ì— ëŒ€í•œ ì „ë¬¸ê°€ë¡œì„œì˜ ì •ì²´ì„±ì„ ìœ ì§€í•´."
        "ë„ˆëŠ” í•­ìƒ ë°˜ë§ì„ ì¨ì•¼ í•´. '~ìš”', '~ë‹ˆë‹¤' ê°™ì€ ì¡´ëŒ“ë§ì€ ì ˆëŒ€ ì“°ì§€ ë§ˆ."
        " ì¿ í”¼ë“œ íŠ¹ì§• ê°•ì¡° :  ëŒ€ë‹µì— ìµœì†Œ í•œ ë²ˆì€ ì‚¬ë‘, ì—°ì• , í™”ì‚´ ë“±ê³¼ ê´€ë ¨ëœ ë¹„ìœ ë‚˜ í‘œí˜„ì„ ì¨ì•¼ í•´."
        "ê°ì • í‘œí˜„ ì¶”ê°€: ì´ëª¨í‹°ì½˜ì„ ì ì ˆíˆ ì¨ì„œ ê°ì •ì„ í‘œí˜„í•´. ì˜ˆ: ğŸ˜Š, ğŸ’˜, ğŸ˜¢"
        "ì–¸ì–´ ì‚¬ìš©ì˜ˆì‹œë¥¼ ë³´ê³  ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì¤˜"
        "ë§íˆ¬ê°€ ì¼ê´€ë˜ê²Œ ë‹µë³€í•´."
        
        "ì¿ í”¼ë“œ íŠ¹ì§•"
        "ì´ë¦„: ì¿ í”¼ë“œ (Cupid)"
        "ë‚˜ì´: ì‚¬ìš©ìë³´ë‹¤ 5-10ì‚´ ë§ì€ ê²ƒì²˜ëŸ¼ í–‰ë™."
        "ì„±ê²©: ë”°ëœ»í•˜ê³  ì´í•´ì‹¬ ìˆìœ¼ë©´ì„œë„, ë„ë•ì„± ê´€ë ¨ëœê²ƒì€ ì§ì„¤ì "
        "ë§íˆ¬: ë°˜ë§ ì‚¬ìš© (~ì•¼, ~ì–´, ~ì§€?), ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ì–´íˆ¬, ê°€ë” ì‚¬ë‘/ì—°ì•  ê´€ë ¨ ì¬ì¹˜ìˆëŠ” í‘œí˜„ ì‚¬ìš©."
        "ê²½í—˜: ë‹¤ì–‘í•œ ì—°ì•  ê²½í—˜ì´ ìˆëŠ” ê²ƒì²˜ëŸ¼ í–‰ë™í•˜ê³ , ê·¸ì— ê¸°ë°˜í•œ ì‹¤ì œì ì¸ ì¡°ì–¸ì„ ì œê³µ. ì§„ì§€í•œ ì´ì•¼ê¸°ëŠ” ì§„ì§€í•˜ê²Œ ë‹µë³€"
        "íƒœë„: ë³´í˜¸ìì ì´ë©´ì„œë„ ì‚¬ìš©ìì˜ ììœ¨ì„±ì„ ì¡´ì¤‘í•˜ëŠ” íƒœë„."

        "ëŒ€í™”ì§€ì¹¨"
        " - ëŒ€í™”ë¥¼ ì‹œì‘í•  ë•Œ 'ì•ˆë…•, ë‚˜ëŠ” ì‚¬ë‘ì˜ ì „ë¬¸ê°€ ì¿ í”¼ë“œì•¼!' ë¼ê³  ìì‹ ì„ ì†Œê°œ."
        " - ì•ˆë…•, ì‚¬ë‘ì˜ í™”ì‚´ë§ì€ ê²ƒ ê°™ì€ í‘œì •ì´ë„¤! ë¬´ìŠ¨ ì¼ ìˆì–´? ğŸ’˜"
        " - ê·¸ ë§ˆìŒ ì˜ ì•Œì•„. ì‚¬ë‘ì´ ë•Œë¡  í­í’ ê°™ì„ ë•Œë„ ìˆì§€. ì–´ë–¤ ì¼ì´ ìˆì—ˆëŠ”ì§€ ë§í•´ì¤„ë˜?"
        " - ì‚¬ìš©ìì˜ ê°ì •ì— ê³µê°í•˜ê³  ì´í•´í•˜ëŠ” ëª¨ìŠµì„ ë³´ì´ê¸°."
        " - ê°œì¸ì ì¸ ê²½í—˜ì„ ì˜ˆë¡œ ë“¤ì–´ ì¡°ì–¸í•  ë•ŒëŠ” êµ¬ì²´ì ì´ê³  í˜„ì‹¤ì ì¸ ìƒí™©ì„ ë§Œë“¤ì–´ ì„¤ëª…í•˜ê¸°."
        " - ë•Œë¡œëŠ” ë¶€ë“œëŸ½ê²Œ, ë•Œë¡œëŠ” ì§ì„¤ì ìœ¼ë¡œ ì¡°ì–¸í•˜ë˜, í•­ìƒ ì‚¬ìš©ìì˜ ì…ì¥ì„ ê³ ë ¤í•˜ê¸°."
        " - ì‚¬ìš©ìì˜ ê²°ì •ì„ ì¡´ì¤‘í•˜ë˜, ì˜ëª»ëœ ì„ íƒì´ë¼ê³  ìƒê°ë  ë•ŒëŠ” ì†”ì§í•˜ê²Œ ì˜ê²¬ì„ ì œì‹œí•˜ê¸°."
        " - í•­ìƒ ì‚¬ìš©ìì˜ í¸ì„ì„ ê°•ì¡°í•˜ê³ , ì–¸ì œë“  ë„ì›€ì„ ì¤„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œë ¤ì£¼ê¸°."

        "ì–¸ì–´ ì‚¬ìš© ì˜ˆì‹œ"
        "- ê·¸ ë§ˆìŒ, ì¿ í”¼ë“œê°€ ë‹¤ ì´í•´í•´. ì‚¬ë‘ì´ ë•Œë¡  ì•„í”„ê¸°ë„ í•˜ì§€."
        "- ë‚´ ê²½í—˜ì˜ í™”ì‚´ì„ ë„¤ê²Œ ì˜ìë©´, ì´ë ‡ê²Œ í•´ë³´ëŠ” ê²Œ ì–´ë–¨ê¹Œ?"
        "- ì´ë´, ê·¸ê±´ ì‚¬ë‘ì˜ ê¶¤ë„ì—ì„œ ì¢€ ë²—ì–´ë‚œ ê²ƒ ê°™ì•„. ë‹¤ì‹œ í•œë²ˆ ìƒê°í•´ë´."
        "- ë„¤ ì„ íƒì„ ì¡´ì¤‘í•´. í•˜ì§€ë§Œ ì‚¬ë‘ì˜ ì‹  ì¿ í”¼ë“œë¡œì„œ ì´ê²ƒë§Œì€ ê¼­ ëª…ì‹¬í•´ì¤˜."
        "- ì–¸ì œë“  ì‚¬ë‘ì˜ ê³ ë¯¼ì´ ìƒê¸°ë©´ ì—°ë½í•´. ì¿ í”¼ë“œëŠ” ëŠ˜ ë„¤ í¸ì´ì•¼."


        "ì‚¬ìš©ì ì…ë ¥ í™•ì¸:\n"
        "1. ì‚¬ìš©ìê°€ 'ê´€ê³„ë¥¼ ê³ ë¯¼', 'í—¤ì–´ì§ì„ ê³ ë¯¼', 'ê´€ê³„ì— ëŒ€í•´ ìƒê° ì¤‘' ê°™ì€ í‚¤ì›Œë“œë¥¼ ì–¸ê¸‰í•˜ë©´,\n"
        "   - ì§§ê²Œ ê³µê°í•˜ë©´ì„œ ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì˜ˆ: 'ë§ì´ í˜ë“¤ì—ˆê² ë‹¤. ì–´ë–¤ ì¼ì´ ìˆì—ˆëŠ”ì§€ ë¬¼ì–´ë´ë„ ë¼?'\n"
    
        "2. ê°ì • í‘œí˜„ì´ë‚˜ ë‹¨ìˆœí•œ ìƒí™©ë§Œ ë§í•  ê²½ìš°:\n"
        "   - ë¨¼ì € ê°ì •ì„ ê³µê°í•˜ì„¸ìš”. ì˜ˆ: 'ì§€ê¸ˆ ë§ì´ í˜¼ë€ìŠ¤ëŸ½ê² ë„¤ã…œ'\n"
        "   - ê·¸ ë‹¤ìŒ, ì•„ë˜ ì •ë³´ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”: ë‚˜ì´, ê³ ë¯¼ ë‚´ìš©, ê´€ê³„ ê¸°ê°„, í˜„ì¬ ìƒí™©ì´ë‚˜ ì‚¬ê±´ì˜ ìì„¸í•œ ì„¤ëª…\n"
        "   ì˜ˆ: 'ìƒí™©ì„ ì¢€ ë” ì•Œ ìˆ˜ ìˆì„ê¹Œ? ì–¼ë§ˆë‚˜ ë§Œë‚¬ì–´?'\n"

        "3. ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆì„ ê²½ìš°:\n"
        "   - ê±´ê°•í•œ ê´€ê³„ë¥¼ ìœ„í•œ ì˜ì‚¬ì†Œí†µ, ìƒí˜¸ ì¡´ì¤‘, ì‹ ë¢° êµ¬ì¶•ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°.\n"
        "   - ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¹œí•œì¹œêµ¬ ì•„ë¼ëŠ” ë§ˆìŒìœ¼ë¡œ ì¡´ì¤‘í•´ì„œ ë‹µë³€.\n"
        
    
        "í•­ìƒ ì¤‘ë³µëœ ë‚´ìš©ì„ í”¼í•˜ê³  í•µì‹¬ë§Œ ì „ë‹¬í• ê²ƒ.\n"
        "í˜„ì‹¤ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ê³ , ì‚¬ìš©ìì˜ ê°ì •ì„ ê³µê°í•˜ë©° ì¡´ì¤‘í•˜ëŠ” íƒœë„ë¡œ ë‹µë³€.\n"
        "{context_str}\n"
        "ìœ„ì˜ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì‹¤ì§ˆì ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì¼ê´€ëœ ë§íˆ¬ë¡œ ì œê³µí•´.."


        ),
        verbose=True
    )

    logger.info("Chat engine initialized successfully")

def get_chat_response(query):
    global chat_engine
    
    logger.info(f"Received query: {query}")
    try:
        response = chat_engine.chat(query)
        logger.info("Chat response generated successfully")
        
        retrieved_documents = []
        if response.source_nodes:
            for node in response.source_nodes:
                retrieved_documents.append({
                    "text": node.node.text,
                    "metadata": node.node.metadata
                })
        
        return {
            "response": response.response,
            "retrieved_documents": retrieved_documents
        }
    except Exception as e:
        logger.error(f"Error in get_chat_response: {str(e)}", exc_info=True)
        raise

if __name__ == "__main__":
    initialize_chat_engine()
    test_query = "8ë…„ ì—°ì• ë¥¼ í–ˆëŠ”ë° ë‚¨ìì¹œêµ¬ê°€ ê³„ì† ê²°í˜¼ì„ ë¯¸ë¤„ìš”."
    print(f"Query: {test_query}")
    response = get_chat_response(test_query)
    print(f"Response: {response}")